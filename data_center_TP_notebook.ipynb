{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89f6f5cc-e740-4a4c-aebf-fd02941b9979",
   "metadata": {},
   "source": [
    "# Optimization for Machine Learning: Computer Lab 1\n",
    "\n",
    "## 2. Preprocessing the data\n",
    "\n",
    "Here, we load the data, standardize it, and set it in the appropriate shape for performing linear regression. You do not need to complete anything in this section; however it is important that you understand what the code is doing. See the pdf instructions for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d81959-fde9-4460-8785-3ac9c2091f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabeb4b7-d0dc-4632-938d-39b450f5c6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "data_matrix_train, COP_train, data_matrix_test, COP_test, names = np.load('data_center_data_matrix.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d092d24-1160-4af6-a7f1-42fde0031f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# centering and normalizing the matrix\n",
    "matrix_mean = np.mean(data_matrix_train, axis=0)\n",
    "M = data_matrix_train - matrix_mean\n",
    "\n",
    "matrix_std = np.std(M, axis=0)\n",
    "M = M / matrix_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21679aa7-a9c2-40d1-819f-2a324da79d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfbeaf2-eb2f-4fc8-8da6-4cdd655529b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the corresponding matrices A,b for linear regression\n",
    "A = np.hstack([M, np.ones((M.shape[0],1)), -(M.T * COP_train[:,3]).T])\n",
    "b = COP_train[:,3]\n",
    "\n",
    "# Building the same matrices for the test set\n",
    "M_test = (data_matrix_test - matrix_mean) / matrix_std\n",
    "A_test = np.hstack([M_test, np.ones((M_test.shape[0],1)), -(M_test.T * COP_test[:,3]).T])\n",
    "b_test = COP_test[:,3]\n",
    "\n",
    "d = A.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc974f0-0eb1-46db-af33-b27f232bc4ec",
   "metadata": {},
   "source": [
    "## 3. Ordinary least squares\n",
    "\n",
    "We now wish to solve the problem\n",
    "$$\n",
    "\\min_{w \\in \\mathbb{R}^d} \\frac 12 \\|Aw-b\\|_2^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f05c04a-ccb8-4781-a62f-7cf42961d46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question 3.2: solve with the numpy least squares solver\n",
    "\n",
    "# COMPLETE HERE\n",
    "# w_least_squares = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe953e31-a214-4ba9-9243-79687c7244a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question 3.3\n",
    "\n",
    "# COMPLETE HERE\n",
    "# test_error = ...\n",
    "# print(\"Test error for least squares solution : \", test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c2b206-fcb6-4ea3-98c9-e730f180d1d4",
   "metadata": {},
   "source": [
    "### Adding $\\ell_2$ regularization\n",
    "\n",
    "In order to improve the performance on the test set, we add $\\ell_2$ regularization:\n",
    "\n",
    "$$\n",
    "\\min_{w \\in \\mathbb{R}^d} \\frac 12 \\|Aw-b\\|_2^2 + \\frac \\lambda 2 \\|w\\|_2^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec09c5bf-adcf-44f9-b7a5-a86052bbab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_l2 = 1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6463cebb-7977-4291-acb3-5ff18c4db357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3.5\n",
    "def f(w):\n",
    "    # COMPLETE HERE\n",
    "\n",
    "def grad_f(w):\n",
    "    # COMPLETE HERE\n",
    "\n",
    "def gradient_descent(f, grad_f, w0, gamma, max_iter):\n",
    "    w = w0.copy()\n",
    "    \n",
    "    f_values = []\n",
    "    gradient_norms = []\n",
    "\n",
    "    for t in range(max_iter):\n",
    "        # COMPLETE HERE \n",
    "        # w = ...\n",
    "        \n",
    "        f_values.append(f(w))\n",
    "        gradient_norms.append(np.linalg.norm(grad_f(w)))\n",
    "        \n",
    "    return w, f_values, gradient_norms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b45d85-6ed0-4cc9-9759-69ee4cbb08f1",
   "metadata": {},
   "source": [
    "For finding the appropriate step size range, we need to estimate the Lipschitz constant of the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92be2760-b2c4-408b-8c3c-309409c1e12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE HERE\n",
    "L = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1f43ef-59e7-4e40-a1cd-a0b154b38e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE HERE\n",
    "w0 = ...\n",
    "step_size = ...\n",
    "max_iter = ...\n",
    "\n",
    "w_GD, f_values_GD, gradient_norms_GD = gradient_descent(f, grad_f, w0, step_size, max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b213c567-b03f-4351-8bf4-21d1f2c529b0",
   "metadata": {},
   "source": [
    "We now compute the evolution of function values and gradient norm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8208d8f1-14eb-4606-acbe-5799105c08a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us plot the result \n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(gradient_norms_GD)\n",
    "axes[0].semilogy()\n",
    "axes[0].set_ylabel(\"Gradient norm\")\n",
    "\n",
    "axes[1].plot(f_values_GD)\n",
    "axes[1].set_ylabel(\"Function values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f65a6-4a51-49be-9398-16d77b3dfd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3.6 \n",
    "\n",
    "test_error_l2 = # COMPLETE HERE\n",
    "print(\"Test error for l2 penalized solution : \", test_error_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817f6aba-fb0f-4ba2-8fa2-2e6279947610",
   "metadata": {},
   "source": [
    "What do you observe ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c6331c-8189-434b-9e9b-35f4680a15bf",
   "metadata": {},
   "source": [
    "### Line search\n",
    "\n",
    "The step size given by theory is can be too conservative in practice. We propose to implement a backtracking line search procedure to find a better one automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892386dc-3fb6-489d-8331-f3dbb1f10852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3.7\n",
    "\n",
    "def gradient_descent_line_search(f, grad_f, w0, gamma_0, max_iter):\n",
    "    w = w0.copy()\n",
    "\n",
    "    # initial step size\n",
    "    gamma = gamma_0.copy() \n",
    "    \n",
    "    f_values = []\n",
    "    gradient_norms = []\n",
    "\n",
    "    for t in range(max_iter):\n",
    "        # COMPLETE HERE\n",
    "        # while ...\n",
    "            \n",
    "        f_values.append(f(w))\n",
    "        gradient_norms.append(np.linalg.norm(grad_f(w)))\n",
    "        \n",
    "    return w, f_values, gradient_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae25f5c1-3bfc-445c-81d3-197b9b2f6ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE HERE\n",
    "w0 = ...\n",
    "step_size = ...\n",
    "max_iter = ...\n",
    "\n",
    "w_GD_LS, f_values_GD_LS, gradient_norms_GD_LS = gradient_descent_line_search(f, grad_f, w0, step_size, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83db2bcf-2370-4cb6-88f3-d3211d55fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us plot the result \n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(gradient_norms_GD_LS)\n",
    "axes[0].semilogy()\n",
    "axes[0].set_ylabel(\"Gradient norm with line search\")\n",
    "\n",
    "axes[1].plot(f_values_GD_LS)\n",
    "axes[1].set_ylabel(\"Function values with line search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8373ae96-3b06-433a-8d53-ac096c7f5fd7",
   "metadata": {},
   "source": [
    "### Accelerated gradient method\n",
    "For a faster algorithm, we could implement accelerated gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c52e42e-2854-44ff-9afc-ed77f5833367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3.8 (optional) \n",
    "\n",
    "def accelerated_gradient_descent(f, grad_f, w0, gamma, max_iter):\n",
    "    # COMPLETE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193e6bce-8df6-4672-8ecd-698f89f173c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE HERE\n",
    "w0 = ...\n",
    "step_size = ...\n",
    "max_iter = ...\n",
    "\n",
    "w_AGD, f_values_AGD, gradient_norms_AGD = accelerated_gradient_descent(f, grad_f, w0, step_size, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05550c3-9a3b-431b-b3f7-d3abe82d6453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us plot the result \n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(gradient_norms_GD, label = \"gradient descent\")\n",
    "axes[0].plot(gradient_norms_AGD, label = \"accelerated gradient descent\")\n",
    "axes[0].semilogy()\n",
    "axes[0].set_ylabel(\"Gradient norm\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(f_values_GD, label = \"gradient descent\")\n",
    "axes[1].plot(f_values_AGD, label = \"accelerated gradient descent\")\n",
    "axes[1].set_ylabel(\"Function values\")\n",
    "axes[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d4b5f8-70e0-4261-8675-3427fa548a90",
   "metadata": {},
   "source": [
    "What do you observe regarding the convergence speed ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8d11cb-4fdf-4e35-b1b6-9f196492e4ca",
   "metadata": {},
   "source": [
    "## 4. Adding $\\ell_1$ regularization (Lasso)\n",
    "\n",
    "We now solve \n",
    "\n",
    "$$\n",
    "\\min_{w \\in \\mathbb{R}^d} \\frac 12 \\|Aw-b\\|_2^2 + \\lambda \\|w\\|_1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f9f212-958b-4597-9f53-12e4e8cef39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_l1 = 1e3\n",
    "\n",
    "## Question 4.2\n",
    "def prox_l1(x, mu = 1.):\n",
    "    \"\"\"compute the proximal operator of mu * |x|_1\n",
    "    \"\"\"\n",
    "    # COMPLETE HERE\n",
    "    # ....\n",
    "\n",
    "def proximal_gradient_descent(f, grad_f, w0, gamma, max_iter):\n",
    "    w = w0.copy()\n",
    "\n",
    "    f_values = []\n",
    "    gradient_norms = []\n",
    "\n",
    "    for t in range(max_iter):\n",
    "        # COMPLETE HERE\n",
    "        # w = ....\n",
    "\n",
    "        f_values.append(f(w))\n",
    "        gradient_norms.append(np.linalg.norm(grad_f(w)))\n",
    "        \n",
    "    return w, f_values, gradient_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fab019-8483-4ddd-8e5f-317180db662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE HERE\n",
    "w0 = ...\n",
    "step_size = ...\n",
    "max_iter = ...\n",
    "\n",
    "w_PGD, f_values_PGD, gradient_norms_PGD = proximal_gradient_descent(f, grad_f, w0, step_size, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0535dfab-8e85-4567-bbdf-998f1e805e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4.3\n",
    "\n",
    "test_error_l1 = # COMPLETE HERE\n",
    "print(\"Test error for l1 penalized solution : \", test_error_l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4485f91-4e46-462f-859c-ebfb40890115",
   "metadata": {},
   "source": [
    "Compare with the previous test errors. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74462a51-8c73-4978-bd94-026e5d7e023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us examine the solution\n",
    "plt.plot(w_GD, label = \"l2 solution\")\n",
    "plt.plot(w_PGD, label = \"l1 solution\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f530b3b2-25fa-462a-ac49-0bf698c186f3",
   "metadata": {},
   "source": [
    "What do you observe regarding the difference in **structure** of the two solutions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2682484e-06db-428c-9cfa-b9255cf8e7db",
   "metadata": {},
   "source": [
    "## [BONUS] Tuning the penalization parameter\n",
    "\n",
    "How to find the best solution among all those that were comptued? How to choose the penalization parameter $\\lambda$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64a7f78b-ff3b-4a2a-a4df-b7028dd65912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your method here..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
